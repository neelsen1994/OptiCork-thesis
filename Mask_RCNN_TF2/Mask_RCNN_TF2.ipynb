{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jG2_N_m7KuuC",
    "outputId": "260d6b22-c9c1-4fdf-e8dc-3d9dadff3adf"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BmU09dsLIpJ",
    "outputId": "d2cfffdb-4ce1-4c39-a381-19f6c61aaf50"
   },
   "outputs": [],
   "source": [
    "!python setup.py clean --all install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwVj4CXIMQXa",
    "outputId": "3cdb0584-2f0a-48ab-d1a7-14df18fa7f97"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/akTwelve/Mask_RCNN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX5R_PM_NBKs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# Root directory of the project\n",
    "#ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "#sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "#sys.path.append('./samples/cork')\n",
    "import corks\n",
    "\n",
    "#sys.path.append(ROOT_DIR)\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvxt-JNwNOBk",
    "outputId": "77cdad08-1ea2-44ce-b72f-cf000f8d0f13"
   },
   "outputs": [],
   "source": [
    "!python3 corks.py train --dataset='./datasets/cork' --weights=coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwpoC6aJ2GiB",
    "outputId": "ab18eef8-070a-4e8f-e3a3-6dd33b5263d9"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lAugyKFjUNz"
   },
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KtdaoIrOM_6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn.model import log\n",
    "from mrcnn import model as modellib, utils\n",
    "from corks import CorkDataset\n",
    "from mrcnn import visualize\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kmWhhVUkTts"
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SW3E3eIBkbOz",
    "outputId": "52d5f1b7-56b0-4643-bfad-6998032750a2"
   },
   "outputs": [],
   "source": [
    "if os.path.abspath(os.getcwd()) != '/tf/notebooks/hdd_1/sen/MyCode/Mask_RCNN_TF2':\n",
    "    ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "    # Import Mask RCNN\n",
    "    sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "# Root directory of the project\n",
    "\n",
    "class InferenceConfig(corks.CorkConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "config = InferenceConfig()\n",
    "\n",
    "config.DETECTION_MIN_CONFIDENCE = 0.7\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='./logs')\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = './logs/cork20210429T1106_all_aug_withLR0001/mask_rcnn_cork_0060.h5'\n",
    "#model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "dataset_val = CorkDataset()\n",
    "dataset_val.load_cork('./datasets/cork', \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Running evaluation on test images.\")\n",
    "\n",
    "mrgData={}\n",
    "t_prediction = 0\n",
    "t_start = time.time()\n",
    "\n",
    "for i, image_id in enumerate(dataset_val.image_ids):\n",
    "        # Load image and run detection\n",
    "        image = dataset_val.load_image(image_id)\n",
    "        original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config, image_id)\n",
    "        #log(\"original_image\", original_image)\n",
    "        #log(\"image_meta\", image_meta)\n",
    "        #log(\"gt_class_id\", gt_class_id)\n",
    "        #log(\"gt_bbox\", gt_bbox)\n",
    "        #log(\"gt_mask\", gt_mask)\n",
    "\n",
    "        fPath = dataset_val.image_info[image_id]['path']\n",
    "        words = fPath.split('/')\n",
    "        fname = words[-1]\n",
    "        fnameGT='GT'+str(i)+fname\n",
    "        fnameP='P'+str(i)+fname\n",
    "        visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, dataset_val.class_names, title=fnameGT, figsize=(8, 8))\n",
    "        \n",
    "        \n",
    "        #plt.savefig(os.path.join('GroundT',fname),bbox_inches='tight')\n",
    "        print(\"Image File Name\", fname)\n",
    "        # Detect objects\n",
    "        t = time.time()\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        \n",
    "        t_prediction += (time.time() - t)\n",
    "        print(\"Pred Time:\", (time.time() - t))\n",
    "        fname_json=fname.split('.')[0] + '.json'\n",
    "        print(fname_json)\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], title=fnameP, ax=get_ax())\n",
    "        #plt.savefig(os.path.join('Prediction',fname),bbox_inches='tight')\n",
    "        r['masks']=r['masks'].astype(int).tolist()\n",
    "        r['rois']=r['rois'].tolist()\n",
    "        r['class_ids']=r['class_ids'].tolist()\n",
    "        r['scores']=r['scores'].tolist()\n",
    "  \n",
    "        #with open(os.path.join('json_predictions',fname_json), 'w') as outfile:\n",
    "        #    json.dump(r, outfile)\n",
    "        \n",
    "\n",
    "print(\"Prediction time: {}. Average {}/image\".format(t_prediction, t_prediction / len(dataset_val.image_ids)))\n",
    "print(\"Total time: \", time.time() - t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.abspath(os.getcwd()) != '/tf/notebooks/hdd_1/sen/MyCode/Mask_RCNN_TF2':\n",
    "    ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "    # Import Mask RCNN\n",
    "    sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "\n",
    "class InferenceConfig(corks.CorkConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='./logs')\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "path = './datasets/cork/test'\n",
    "files = sorted(os.listdir(path))\n",
    "\n",
    "t_prediction = 0\n",
    "t_start = time.time()\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    img_path = os.path.join(path,file)\n",
    "    \n",
    "    print(file)\n",
    "    print(i)\n",
    "    image = skimage.io.imread(img_path)\n",
    "    t = time.time()\n",
    "    r = model.detect([image], verbose=0)[0]\n",
    "    t_prediction += (time.time() - t)\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'])\n",
    "\n",
    "print(\"Number of test cases:\", len(files))        \n",
    "print(\"Prediction time: {}. Average {}/image\".format(t_prediction, t_prediction / len(files)))\n",
    "print(\"Total time: \", time.time() - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "#image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "AP_Range=[]\n",
    "A_F1 = []\n",
    "A_Prec = []\n",
    "A_Rec = []\n",
    "iou_scores=[]\n",
    "totalTP = 0\n",
    "totalFP = 0\n",
    "totalFN = 0\n",
    "for i,image_id in enumerate(dataset_val.image_ids):\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config,\n",
    "                               image_id)\n",
    "    #molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "    # Run object detection\n",
    "    t = time.time()\n",
    "    results = model.detect([image], verbose=0)\n",
    "    pred_time = time.time() - t\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    gt_match,pred_match,overlap = utils.compute_matches(gt_bbox, gt_class_id, gt_mask,\n",
    "        r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    \n",
    "    AP_rng =utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    \n",
    "    if math.isnan(AP_rng):\n",
    "        AP_rng=0\n",
    "    print(\"AP RANGE\",AP_rng)\n",
    "    prec, rec, f1 = utils.compute_f1_score(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    \n",
    "    fPath = dataset_val.image_info[image_id]['path']\n",
    "    words = fPath.split('/')\n",
    "    fname = words[4]\n",
    "    FP = np.count_nonzero(pred_match == -1)\n",
    "    TP = len(pred_match) - FP\n",
    "    FN = np.count_nonzero(gt_match == -1)\n",
    "    print(\"File Name: \", fname + \"-----------------------------\")\n",
    "    #print(\"GT\",gt_match)\n",
    "    #print(\"PRED\",pred_match)\n",
    "    if FP == 0 and TP == 0 and FN == 0:\n",
    "      AP = 1.0\n",
    "    elif len(gt_match)==0 and FP > 0:\n",
    "      AP = 0.0\n",
    "    elif len(pred_match)==0 and FN > 0:\n",
    "      AP = 0.0\n",
    "    #print(\"AP\", AP)\n",
    "    \n",
    "    iou=utils.compute_overlaps_masks(gt_mask,r['masks'])\n",
    "    if len(iou)==0:\n",
    "        iou=0\n",
    "    else:\n",
    "        iou=np.sum(iou,axis=1)\n",
    "        iou=np.mean(iou)\n",
    "        \n",
    "    iou_scores.append(iou)\n",
    "    \n",
    "    print(\"Prediction Time:\",pred_time)\n",
    "    print(\"False Positive:\",FP)\n",
    "    print(\"True Positive:\",TP)\n",
    "    print(\"False Negative:\",FN)\n",
    "    print(\"Precision\",prec)\n",
    "    print(\"Recall\",rec)\n",
    "    print(\"F1-score\",f1)\n",
    "    print(\"IoU Score\",iou)\n",
    "    print(\"AP\",AP)\n",
    "    #try:\n",
    "    #    p = TP / (TP + FP)\n",
    "    #    r = TP / (TP + FN)\n",
    "    #except:\n",
    "    #    if FP == 0 and TP == 0 and FN == 0:\n",
    "    #        p = 1\n",
    "    #        r = 1\n",
    "    #    else:\n",
    "    #        p = 0\n",
    "    #        r = 1\n",
    "    #    pass\n",
    "    #print(\"PRECISION MAN\",p)\n",
    "    #print(\"RECALL MAN\",r)\n",
    "    \n",
    "    totalTP = totalTP + TP\n",
    "    totalFP = totalFP + FP\n",
    "    totalFN = totalFN + FN\n",
    "    print(\"####################################################\")\n",
    "    APs.append(AP)\n",
    "    AP_Range.append(AP_rng)\n",
    "    A_F1.append(f1)\n",
    "    A_Prec.append(prec)\n",
    "    A_Rec.append(rec)\n",
    "    \n",
    "print(\"Summary:-\")\n",
    "print(\"Confidence Threshold:\", config.DETECTION_MIN_CONFIDENCE)\n",
    "print(\"Total True Positive:\", totalTP)\n",
    "print(\"Total False Positive:\", totalFP)\n",
    "print(\"Total False Negative:\", totalFN)\n",
    "print(\"Average Recall:\", np.mean(A_Rec))\n",
    "print(\"Average Precision:\", np.mean(A_Prec))\n",
    "print(\"Mean F1-Score:\", np.mean(A_F1))\n",
    "print(\"Average IoU Score\",np.mean(iou_scores))\n",
    "print(\"mAP@0.5: \", np.mean(APs))\n",
    "print(\"mAP@0.5-0.95: \", np.mean(AP_Range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mask_RCNN_TF2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
