{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask RCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../Mask_RCNN_TF2\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.model import log\n",
    "\n",
    "#sys.path.append('./samples/cork')\n",
    "import corks\n",
    "\n",
    "#sys.path.append(ROOT_DIR)\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from corks import CorkDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "class InferenceConfig(corks.CorkConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "config = InferenceConfig()\n",
    "\n",
    "config.DETECTION_MIN_CONFIDENCE = 0.7\n",
    "\n",
    "model_mrcnn = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='./logs')\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = '../Mask_RCNN_TF2/logs/cork20210429T1106_all_aug_withLR0001/mask_rcnn_cork_0060.h5'\n",
    "#model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model_mrcnn.load_weights(model_path, by_name=True)\n",
    "\n",
    "dataset_val = CorkDataset()\n",
    "dataset_val.load_cork('../Mask_RCNN_TF2/datasets/cork', \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Running evaluation on test images.\")\n",
    "\n",
    "mrgData={}\n",
    "t_prediction = 0\n",
    "t_start = time.time()\n",
    "\n",
    "for i, image_id in enumerate(dataset_val.image_ids):\n",
    "        # Load image and run detection\n",
    "        image = dataset_val.load_image(image_id)\n",
    "        original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config, image_id)\n",
    "        #log(\"original_image\", original_image)\n",
    "        #log(\"image_meta\", image_meta)\n",
    "        #log(\"gt_class_id\", gt_class_id)\n",
    "        #log(\"gt_bbox\", gt_bbox)\n",
    "        #log(\"gt_mask\", gt_mask)\n",
    "        print(\"ORINGINAL IMG SHAPE\", original_image.shape)\n",
    "        \n",
    "        fPath = dataset_val.image_info[image_id]['path']\n",
    "        words = fPath.split('/')\n",
    "        fname = words[-1]\n",
    "        fnameGT='GT'+str(i)+fname\n",
    "        fnameP='P'+str(i)+fname\n",
    "        visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, dataset_val.class_names, title=fnameGT, figsize=(8, 8))\n",
    "        \n",
    "        \n",
    "        #plt.savefig(os.path.join('GroundT',fname),bbox_inches='tight')\n",
    "        print(\"Image File Name\", i)\n",
    "\n",
    "        # Detect objects\n",
    "        t = time.time()\n",
    "        \n",
    "        r = model_mrcnn.detect([image], verbose=0)[0]\n",
    "        #print(\"PRED SHAPE\", r['masks'].shape)\n",
    "        t_prediction += (time.time() - t)\n",
    "        print(\"Pred Time:\", (time.time() - t))\n",
    "        fname_json=fname.split('.')[0] + '.json'\n",
    "        print(fname_json)\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], title=fnameP, ax=get_ax())\n",
    "        #plt.savefig(os.path.join('Prediction',fname),bbox_inches='tight')\n",
    "        \n",
    "        r['masks']=r['masks'].astype(int).tolist()\n",
    "        r['rois']=r['rois'].tolist()\n",
    "        r['class_ids']=r['class_ids'].tolist()\n",
    "        r['scores']=r['scores'].tolist()\n",
    "        \n",
    "        \n",
    "        #with open(os.path.join('json_predictions',fname_json), 'w') as outfile:\n",
    "        #    json.dump(r, outfile)\n",
    "        \n",
    "\n",
    "print(\"Prediction time: {}. Average {}/image\".format(t_prediction, t_prediction / len(dataset_val.image_ids)))\n",
    "print(\"Total time: \", time.time() - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "#image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "A_F1 = []\n",
    "A_Prec = []\n",
    "A_Rec = []\n",
    "iou_scores=[]\n",
    "totalTP = 0\n",
    "totalFP = 0\n",
    "totalFN = 0\n",
    "for i,image_id in enumerate(dataset_val.image_ids):\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config,\n",
    "                               image_id)\n",
    "    #molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "    # Run object detection\n",
    "    t = time.time()\n",
    "    results = model_mrcnn.detect([image], verbose=0)\n",
    "    pred_time = time.time() - t\n",
    "    r = results[0]\n",
    "    \n",
    "    # Compute AP\n",
    "    gt_match,pred_match,overlap = utils.compute_matches(gt_bbox, gt_class_id, gt_mask,\n",
    "        r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    \n",
    "    prec, rec, f1 = utils.compute_f1_score(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    \n",
    "    fPath = dataset_val.image_info[image_id]['path']\n",
    "    words = fPath.split('/')\n",
    "    fname = words[4]\n",
    "    \n",
    "    iou=utils.compute_overlaps_masks(gt_mask,r['masks'])\n",
    "    if len(iou)==0:\n",
    "        iou=0\n",
    "    else:\n",
    "        iou=np.sum(iou,axis=1)\n",
    "        iou=np.mean(iou)\n",
    "    print(\"IoU Score mean\",iou)\n",
    "    iou_scores.append(iou)\n",
    "    FP = np.count_nonzero(pred_match == -1)\n",
    "    TP = len(pred_match) - FP\n",
    "    FN = np.count_nonzero(gt_match == -1)\n",
    "    print(\"File Name: \", i)\n",
    "    #print(\"GT\",gt_match)\n",
    "    #print(\"PRED\",pred_match)\n",
    "    if FP == 0 and TP == 0 and FN == 0:\n",
    "      AP = 1.0\n",
    "    elif len(gt_match)==0 and FP > 0:\n",
    "      AP = 0.0\n",
    "    elif len(pred_match)==0 and FN > 0:\n",
    "      AP = 0.0\n",
    "    #print(\"AP\", AP)\n",
    "    print(\"Prediction Time:\",pred_time)\n",
    "    print(\"False Positive:\",FP)\n",
    "    print(\"True Positive:\",TP)\n",
    "    print(\"False Negative:\",FN)\n",
    "    print(\"Precision\",prec)\n",
    "    print(\"Recall\",rec)\n",
    "    print(\"F1-score\",f1)\n",
    "    \n",
    "    print(\"AP\",AP)\n",
    "    #try:\n",
    "    #    p = TP / (TP + FP)\n",
    "    #    r = TP / (TP + FN)\n",
    "    #except:\n",
    "    #    if FP == 0 and TP == 0 and FN == 0:\n",
    "    #        p = 1\n",
    "    #        r = 1\n",
    "    #    else:\n",
    "    #        p = 0\n",
    "    #        r = 1\n",
    "    #    pass\n",
    "    #print(\"PRECISION MAN\",p)\n",
    "    #print(\"RECALL MAN\",r)\n",
    "    \n",
    "    totalTP = totalTP + TP\n",
    "    totalFP = totalFP + FP\n",
    "    totalFN = totalFN + FN\n",
    "    print(\"####################################################\")\n",
    "    APs.append(AP)\n",
    "    A_F1.append(f1)\n",
    "    A_Prec.append(prec)\n",
    "    A_Rec.append(rec)\n",
    "    \n",
    "print(\"Summary:-\")\n",
    "print(\"Confidence Threshold:\", config.DETECTION_MIN_CONFIDENCE)\n",
    "print(\"Total True Positive:\", totalTP)\n",
    "print(\"Total False Positive:\", totalFP)\n",
    "print(\"Total False Negative:\", totalFN)\n",
    "print(\"Average Recall:\", np.mean(A_Rec))\n",
    "print(\"Average Precision:\", np.mean(A_Prec))\n",
    "print(\"Mean F1-Score:\", np.mean(A_F1))\n",
    "print(\"Average IoU Score\",np.mean(iou_scores))\n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "ROOT_DIR = os.path.abspath(\"../segmentation_models\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "import json\n",
    "import cv2\n",
    "import skimage.draw\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from skimage import morphology as morph\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using absolute paths\n",
    "DATA_DIR = '/tf/notebooks/hdd_1/sen/MyCode/segmentation_models/data/cork'\n",
    "\n",
    "# load repo with data if it is not exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print('Loading data...')\n",
    "    os.system('git clone https://github.com/alexgkendall/SegNet-Tutorial ./data')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'trainannot')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'valannot')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'testannot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"The base class for dataset classes.\n",
    "    To use it, create a new class that adds functions specific to the dataset\n",
    "    you want to use. For example:\n",
    "\n",
    "    class CatsAndDogsDataset(Dataset):\n",
    "        def load_cats_and_dogs(self):\n",
    "            ...\n",
    "        def load_mask(self, image_id):\n",
    "            ...\n",
    "        def image_reference(self, image_id):\n",
    "            ...\n",
    "\n",
    "    See COCODataset and ShapesDataset as examples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_map=None):\n",
    "        self._image_ids = []\n",
    "        self.image_info = []\n",
    "        # Background is always the first class\n",
    "        self.class_info = [{\"source\": \"\", \"id\": 0, \"name\": \"BG\"}]\n",
    "        self.source_class_ids = {}\n",
    "\n",
    "    def add_class(self, source, class_id, class_name):\n",
    "        assert \".\" not in source, \"Source name cannot contain a dot\"\n",
    "        # Does the class exist already?\n",
    "        for info in self.class_info:\n",
    "            if info['source'] == source and info[\"id\"] == class_id:\n",
    "                # source.class_id combination already available, skip\n",
    "                return\n",
    "        # Add the class\n",
    "        self.class_info.append({\n",
    "            \"source\": source,\n",
    "            \"id\": class_id,\n",
    "            \"name\": class_name,\n",
    "        })\n",
    "\n",
    "    def add_image(self, source, image_id, path, **kwargs):\n",
    "        image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"source\": source,\n",
    "            \"path\": path,\n",
    "        }\n",
    "        image_info.update(kwargs)\n",
    "        self.image_info.append(image_info)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return a link to the image in its source Website or details about\n",
    "        the image that help looking it up or debugging it.\n",
    "\n",
    "        Override for your dataset, but pass to this function\n",
    "        if you encounter images not in your dataset.\n",
    "        \"\"\"\n",
    "        return \"\"\n",
    "\n",
    "    def prepare(self, class_map=None):\n",
    "        \"\"\"Prepares the Dataset class for use.\n",
    "\n",
    "        TODO: class map is not supported yet. When done, it should handle mapping\n",
    "              classes from different datasets to the same class ID.\n",
    "        \"\"\"\n",
    "\n",
    "        def clean_name(name):\n",
    "            \"\"\"Returns a shorter version of object names for cleaner display.\"\"\"\n",
    "            return \",\".join(name.split(\",\")[:1])\n",
    "\n",
    "        # Build (or rebuild) everything else from the info dicts.\n",
    "        self.num_classes = len(self.class_info)\n",
    "        print(\"Num Class\",self.num_classes)\n",
    "        self.class_ids = np.arange(self.num_classes)\n",
    "        self.class_names = [clean_name(c[\"name\"]) for c in self.class_info]\n",
    "        self.num_images = len(self.image_info)\n",
    "        self._image_ids = np.arange(self.num_images)\n",
    "\n",
    "        # Mapping from source class and image IDs to internal IDs\n",
    "        self.class_from_source_map = {\"{}.{}\".format(info['source'], info['id']): id\n",
    "                                      for info, id in zip(self.class_info, self.class_ids)}\n",
    "        self.image_from_source_map = {\"{}.{}\".format(info['source'], info['id']): id\n",
    "                                      for info, id in zip(self.image_info, self.image_ids)}\n",
    "\n",
    "        # Map sources to class_ids they support\n",
    "        self.sources = list(set([i['source'] for i in self.class_info]))\n",
    "        self.source_class_ids = {}\n",
    "        # Loop over datasets\n",
    "        for source in self.sources:\n",
    "            self.source_class_ids[source] = []\n",
    "            # Find classes that belong to this dataset\n",
    "            for i, info in enumerate(self.class_info):\n",
    "                # Include BG class in all datasets\n",
    "                if i == 0 or source == info['source']:\n",
    "                    self.source_class_ids[source].append(i)\n",
    "\n",
    "    def map_source_class_id(self, source_class_id):\n",
    "        \"\"\"Takes a source class ID and returns the int class ID assigned to it.\n",
    "\n",
    "        For example:\n",
    "        dataset.map_source_class_id(\"coco.12\") -> 23\n",
    "        \"\"\"\n",
    "        return self.class_from_source_map[source_class_id]\n",
    "\n",
    "    def get_source_class_id(self, class_id, source):\n",
    "        \"\"\"Map an internal class ID to the corresponding class ID in the source dataset.\"\"\"\n",
    "        info = self.class_info[class_id]\n",
    "        assert info['source'] == source\n",
    "        return info['id']\n",
    "\n",
    "    @property\n",
    "    def image_ids(self):\n",
    "        return self._image_ids\n",
    "\n",
    "    def source_image_link(self, image_id):\n",
    "        \"\"\"Returns the path or URL to the image.\n",
    "        Override this to return a URL to the image if it's available online for easy\n",
    "        debugging.\n",
    "        \"\"\"\n",
    "        return self.image_info[image_id][\"path\"]\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if image.ndim != 3:\n",
    "            image = skimage.color.gray2rgb(image)\n",
    "        # If has an alpha channel, remove it for consistency\n",
    "        if image.shape[-1] == 4:\n",
    "            image = image[..., :3]\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Load instance masks for the given image.\n",
    "\n",
    "        Different datasets use different ways to store masks. Override this\n",
    "        method to load instance masks and return them in the form of am\n",
    "        array of binary masks of shape [height, width, instances].\n",
    "\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                a binary mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # Override this function to load a mask from your dataset.\n",
    "        # Otherwise, it returns an empty mask.\n",
    "        logging.warning(\"You are using the default load_mask(), maybe you need to define your own one.\")\n",
    "        mask = np.empty([0, 0, 0])\n",
    "        class_ids = np.empty([0], np.int32)\n",
    "        return mask, class_ids\n",
    "    \n",
    "# helper function for data visualization\n",
    "def visualize_unet(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "    \n",
    "\n",
    "# classes for data loading and preprocessing\n",
    "class CorkDatasetUNet(Dataset):\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir,\n",
    "            annot_dir,\n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        Dataset.__init__(self)\n",
    "        #self.ids = os.listdir(images_dir)\n",
    "        #self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.ids=[]\n",
    "        self.images_fps=[]\n",
    "        #self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        #self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "\n",
    "        self.add_class(\"Wood\", 1, \"Wood\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        #assert subset in [\"train\", \"val\"]\n",
    "        #dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
    "        annotations = json.load(open(os.path.join(annot_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        #annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. These are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
    "            if type(a['regions']) is dict:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            else:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            self.ids.append(a['filename'])\n",
    "            image_path = os.path.join(images_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "            self.images_fps.append(image_path)\n",
    "            \n",
    "            self.add_image(\n",
    "                \"Wood\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a cork dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"Wood\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.int), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"Wood\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        #\n",
    "        #print(mask.shape)\n",
    "        ##print(\"Class Val\",self.class_values)\n",
    "        ##print(\"Mask Shape\", mask.shape)\n",
    "        ## extract certain classes from mask (e.g. cars)\n",
    "        #masks = [(mask == v) for v in self.class_values]\n",
    "        ##print(\"Masks---\", masks)\n",
    "        #mask = np.stack(masks, axis=-1).astype('float')\n",
    "        #print(\"After Stack\",mask)\n",
    "\n",
    "        mask, class_ids = self.load_mask(i)\n",
    "        mask=np.sum(mask,axis=2)\n",
    "        mask=np.expand_dims(mask,axis=2)\n",
    "\n",
    "        assert np.any(mask) <= 1, \"Overlapping annotations are there!\"\n",
    "        mask = mask.astype(float)\n",
    "\n",
    "\n",
    "        # add background if mask is not binary\n",
    "        if mask.shape[-1] == 1:\n",
    "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "            mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    \n",
    "class Dataloder(keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        # transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return tuple(batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n",
    "            \n",
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "# define heavy augmentations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        #A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        #A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
    "        A.RandomCrop(height=640, width=640, always_apply=True),\n",
    "\n",
    "        #A.GaussNoise(p=0.2),\n",
    "        #A.Perspective(p=0.5),\n",
    "\n",
    "        #A.OneOf(\n",
    "        #    [\n",
    "        #        A.CLAHE(p=1),\n",
    "        #        A.RandomBrightness(p=1),\n",
    "        #        A.RandomGamma(p=1),\n",
    "        #    ],\n",
    "        #    p=0.9,\n",
    "        #),\n",
    "\n",
    "        #A.OneOf(\n",
    "        #    [\n",
    "        #        A.Sharpen(p=1),\n",
    "        #        A.Blur(blur_limit=3, p=1),\n",
    "        #        A.MotionBlur(blur_limit=3, p=1),\n",
    "        #    ],\n",
    "        #    p=0.9,\n",
    "        #),\n",
    "\n",
    "        #A.OneOf(\n",
    "        #    [\n",
    "        #        A.RandomBrightnessContrast(p=1),\n",
    "        #        A.HueSaturationValue(p=1),\n",
    "        #    ],\n",
    "        #    p=0.9,\n",
    "        #),\n",
    "        #A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(1504, 1984)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'efficientnetb3'\n",
    "BATCH_SIZE = 8\n",
    "CLASSES = ['Wood']\n",
    "LR = 0.0001\n",
    "EPOCHS = 50\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "n_classes = 2\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model_unet = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
    "\n",
    "# define optomizer\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model_unet.compile(optim, total_loss, metrics)\n",
    "\n",
    "test_dataset = CorkDatasetUNet(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input),\n",
    ")\n",
    "\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model_unet.load_weights('../segmentation_models/1_ENetB3_lr0001_bs8_epo100_softmax.h5')\n",
    "n = 20\n",
    "ids = np.arange(len(test_dataset))\n",
    "\n",
    "#np.random.choice\n",
    "\n",
    "for i in ids:\n",
    "    \n",
    "    image, gt_mask = test_dataset[i]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    t = time.time()\n",
    "    pr_mask = model_unet.predict(image).round()\n",
    "    pred_time = time.time() - t\n",
    "    print(\"Eval Time-\",pred_time)\n",
    "    print(\"UNET MASK SHAPE\",pr_mask.shape)\n",
    "    visualize_unet(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask[..., 0].squeeze(),\n",
    "        pr_mask=pr_mask[..., 0].squeeze(),\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padIfNeeded(img, h, w):\n",
    "    delta_w = w - img.shape[1]\n",
    "    delta_h = h - img.shape[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "    #color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT)\n",
    "    \n",
    "    return new_im\n",
    "\n",
    "def iou_score(mask1, mask2):\n",
    "    \"\"\"Computes IoU overlaps between two sets of masks.\n",
    "    masks1, masks2: [Height, Width, instances]\n",
    "    \"\"\"    \n",
    "\n",
    "    # intersections and union\n",
    "    intersection = np.sum((mask1 + mask2)==2)\n",
    "    union = np.sum(mask1) + np.sum(mask2) - intersection\n",
    "    if union==0:\n",
    "        return 1\n",
    "    overlaps = intersection / union\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def ensemble_type1(img1,img2, rcnn_scores):\n",
    "    \n",
    "    ch_1 = img1.shape[2]\n",
    "    try:\n",
    "        ch_2 = img2.shape[2]\n",
    "    except:\n",
    "        return img1\n",
    "    \n",
    "    mask=[]\n",
    "    i_unet_ind=np.zeros(ch_1)\n",
    "    j_rcnn_ind=np.zeros(ch_2)\n",
    "    for i in range(ch_1):\n",
    "        for j in range(ch_2):\n",
    "            if np.any(img1[:,:,i]+img2[:,:,j]==2):\n",
    "                m=np.where(img1[:,:,i]+img2[:,:,j]==2,1,0)\n",
    "                mask.append(m)\n",
    "                i_unet_ind[i]=1\n",
    "                j_rcnn_ind[j]=1\n",
    "            \n",
    "        #if vis==0:\n",
    "        #    mask.append(img1[:,:,i])\n",
    "        #    mask.append(img2[:,:,j])\n",
    "        \n",
    "    for i in range(ch_1):\n",
    "        if i_unet_ind[i] == 0:\n",
    "            area=utils.compute_mask_area(np.expand_dims(img1[:,:,i],axis=2))\n",
    "            if area > 500:\n",
    "                mask.append(img1[:,:,i])\n",
    "    \n",
    "    for j in range(ch_2):\n",
    "        if j_rcnn_ind[j] == 0:\n",
    "            area=utils.compute_mask_area(np.expand_dims(img2[:,:,j],axis=2))\n",
    "            if area > 500 and rcnn_scores[j] > 0.95:\n",
    "                mask.append(img2[:,:,j])\n",
    "\n",
    "    try:\n",
    "        mask_ensemble=np.stack(mask,axis=2)\n",
    "    except:\n",
    "        return img1\n",
    "    return mask_ensemble\n",
    "    \n",
    "#image = dataset_val.load_image(0)\n",
    "#new_img = padIfNeeded(image, 1504, 1984)\n",
    "#plt.imshow(new_img)\n",
    "#new_img.shape\n",
    "\n",
    "def bin_mask_splitter(im):\n",
    "    image=im.squeeze()\n",
    "    labeled = morph.label(image, connectivity=2)\n",
    "\n",
    "    mask=[]\n",
    "    for i in np.unique(labeled)[1:]: # skip the first component since it's the background\n",
    "        im_obj = np.zeros(image.shape) \n",
    "        im_obj[labeled == i] = 1\n",
    "        #imsave('sLUel_{:03d}.png'.format(i), im_obj)\n",
    "        mask.append(im_obj)\n",
    "    \n",
    "    if not len(mask):\n",
    "        return im\n",
    "    final=np.stack(mask,axis=2)\n",
    "    return final\n",
    "\n",
    "msk = []\n",
    "mask_unet1 = np.array([[0,0,0,0,0,0],[0,1,1,0,0,0],[0,0,1,1,0,0],[0,0,0,0,0,0]])\n",
    "mask_unet2 = np.array([[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,0,0,1],[0,0,0,0,0,0]])\n",
    "msk.append(mask_unet1)\n",
    "msk.append(mask_unet2)\n",
    "mask_unet=np.stack(msk,axis=2)\n",
    "\n",
    "msk=[]\n",
    "mask_rcnn1 = np.array([[0,1,1,0,0,0],[0,1,1,0,0,0],[0,0,1,1,0,0],[0,0,1,1,0,0]])\n",
    "mask_rcnn2 = np.array([[0,0,0,0,1,1],[0,0,0,0,1,1],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
    "mask_rcnn3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,1,1]])\n",
    "msk.append(mask_rcnn1)\n",
    "msk.append(mask_rcnn2)\n",
    "msk.append(mask_rcnn3)\n",
    "mask_rcnn=np.stack(msk,axis=2)\n",
    "\n",
    "\n",
    "\n",
    "#m=np.where(mask_rcnn2==mask_unet2,mask_rcnn2,0)\n",
    "m=padIfNeeded(mask_unet,20,20)\n",
    "\n",
    "plt.imshow(m[:,:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.array([-1,-1,3,2,-1])\n",
    "#np.cumsum(p > -1)\n",
    "\n",
    "#(np.arange(len(p)) + 1)\n",
    "\n",
    "mAP(mask_rcnn, mask_unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Comparison: U-Net vs Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(len(test_dataset))\n",
    "\n",
    "AP_lst=[]\n",
    "IoU_mean=[]\n",
    "AP_ensLst = []\n",
    "\n",
    "#ids = (15,16)\n",
    "\n",
    "for i in ids:\n",
    "    \n",
    "    image = dataset_val.load_image(i)\n",
    "\n",
    "    config.IMAGE_RESIZE_MODE=\"none\"\n",
    "    orig_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config,i)\n",
    "    \n",
    "    #image_rcnn = image.astype(np.uint8)\n",
    "    #image = dataset_val.load_image(i)\n",
    "    #print(\"MRNN DTP\",image.dtype)\n",
    "    config.IMAGE_RESIZE_MODE=\"square\"\n",
    "    orig_image_vis, image_meta_vis, gt_class_id_vis, gt_bbox_vis, gt_mask_vis =\\\n",
    "        modellib.load_image_gt(dataset_val, config,i)\n",
    "    visualize.display_instances(orig_image_vis, gt_bbox_vis, gt_mask_vis, gt_class_id_vis, dataset_val.class_names, title=\"GT\", figsize=(8, 8))\n",
    "        \n",
    "    \n",
    "    t = time.time()\n",
    "    r = model_mrcnn.detect([image], verbose=0)[0]\n",
    "    \n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], title=fnameP, ax=get_ax())\n",
    "\n",
    "    AP_x, precisions_x, recalls_x, overlaps_x =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    print(\"Mask RCNN mAP\", AP_x)\n",
    "    \n",
    "    rcnn_mask = r['masks'].astype(np.int32)\n",
    "    print(\"RCNN Mask\",rcnn_mask.shape)\n",
    "    \n",
    "    gt_mask=gt_mask.astype(np.int32)\n",
    "    \n",
    "    #For shape mismatch in 1 layer Mask -> [[...]]\n",
    "    if gt_mask.shape[2] == 1:\n",
    "        gt_mask=padIfNeeded(gt_mask, 1504, 1984)\n",
    "        gt_mask=np.expand_dims(gt_mask,axis=2)\n",
    "    #For shape mismatch in empty Mask -> [[]]    \n",
    "    elif gt_mask.shape[2]==0:\n",
    "        if rcnn_mask.shape[2]==0:\n",
    "            print(\"Image Number----------\", i)\n",
    "            print(\"maskrcnn type-\",rcnn_mask.dtype)\n",
    "            print(\"maskrcnn GT Mask TYPE\",gt_mask.dtype)\n",
    "            print(\"unet type-\",unet_mask.dtype)\n",
    "            print(\"maskrcnn Pred mask shape-\",rcnn_mask.shape)\n",
    "            print(\"maskrcnn GT Mask shape\",gt_mask.shape)\n",
    "            print(\"unet mask shape-\",unet_mask.shape)\n",
    "            print(\"---------------------------\")\n",
    "            AP_ensLst.append(1.0)\n",
    "            IoU_mean.append(1.0)\n",
    "            continue\n",
    "        else:\n",
    "            AP_ensLst.append(0.0)\n",
    "            IoU_mean.append(0.0)\n",
    "            continue\n",
    "    else:           \n",
    "        gt_mask=padIfNeeded(gt_mask, 1504, 1984)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rcnn_mask=padIfNeeded(rcnn_mask, 1504, 1984)\n",
    "    \n",
    "    \n",
    "    #UNET mask calculation\n",
    "    image, gt_mask_unet = test_dataset[i]\n",
    "    \n",
    "    #print(\"UNET DTP\",image.dtype)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    unet_mask = model_unet.predict(image).round()\n",
    "    \n",
    "    unet_mask = unet_mask.squeeze()\n",
    "    unet_mask_b4split = unet_mask[:,:,0:1]\n",
    "    \n",
    "    visualize_unet(\n",
    "       unet_mask=unet_mask_b4split[..., 0].squeeze(),\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    )\n",
    "    \n",
    "    unet_mask=bin_mask_splitter(unet_mask_b4split)\n",
    "    unet_mask=unet_mask.astype(np.int32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"======================================\")\n",
    "    print(\"Image Number----------\", i)\n",
    "    print(\"maskrcnn type-\",rcnn_mask.dtype)\n",
    "    print(\"maskrcnn GT Mask TYPE\",gt_mask.dtype)\n",
    "    print(\"unet type-\",unet_mask.dtype)\n",
    "    print(\"maskrcnn Pred mask shape-\",rcnn_mask.shape)\n",
    "    print(\"maskrcnn GT Mask shape\",gt_mask.shape)\n",
    "    print(\"unet mask shape-\",unet_mask.shape)\n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "    AP=mAP(gt_mask,unet_mask)\n",
    "    print(\"AP_Unet\",AP)\n",
    "    AP_lst.append(AP)\n",
    "    \n",
    "    output_mask=ensemble_type1(unet_mask,rcnn_mask, r['scores'])\n",
    "    t_rcnn=time.time()-t\n",
    "    print(\"Pred Time\",t_rcnn)\n",
    "    iou=utils.compute_overlaps_masks(gt_mask,output_mask)\n",
    "    if len(iou)==0:\n",
    "        iou=0\n",
    "    else:\n",
    "        iou=np.sum(iou,axis=1)\n",
    "        iou=np.mean(iou)\n",
    "        \n",
    "    IoU_mean.append(iou)\n",
    "    print(\"IoU Ind mean\",iou)\n",
    "    print(\"MASK AREA\", utils.compute_mask_area(output_mask))\n",
    "    print(\"ensemble mask shape-\",output_mask.shape)\n",
    "    vmask=np.sum(output_mask,axis=2)\n",
    "    vmask=np.expand_dims(vmask,axis=2)\n",
    "    visualize_unet(\n",
    "        pr_mask=vmask[..., 0].squeeze(),\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    )\n",
    "    AP=mAP(gt_mask,output_mask,0.7)\n",
    "    print(\"AP_ensemble\",AP)\n",
    "    AP_ensLst.append(AP)\n",
    "    print(\"===============================\")\n",
    "    \n",
    "print(\"MEAN AP of Unet\", np.mean(AP_lst))\n",
    "print(\"MEAN AP of Ensemble\", np.mean(AP_ensLst))\n",
    "print(\"MEAN IOU of Ensemble\", np.mean(IoU_mean))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Average Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from numpy.linalg import norm\n",
    " \n",
    "def ensemble_prediction(w):\n",
    "    ids = np.arange(len(test_dataset))\n",
    "\n",
    "    avg_iou_rcnn=[]\n",
    "    avg_iou_unet=[]\n",
    "    avg_iou_ens=[]\n",
    "    \n",
    "    avg_dice_rcnn=[]\n",
    "    avg_dice_unet=[]\n",
    "    avg_dice_ens=[]\n",
    "    \n",
    "    \n",
    "    #ids = (8,12,15,16)\n",
    "    \n",
    "    for i in ids:\n",
    "        \n",
    "        image = dataset_val.load_image(i)\n",
    "    \n",
    "        config.IMAGE_RESIZE_MODE=\"none\"\n",
    "        orig_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_val, config,i)\n",
    "        \n",
    "        #image_rcnn = image.astype(np.uint8)\n",
    "        #image = dataset_val.load_image(i)\n",
    "        #print(\"MRNN DTP\",image.dtype)\n",
    "        config.IMAGE_RESIZE_MODE=\"square\"\n",
    "        #orig_image_vis, image_meta_vis, gt_class_id_vis, gt_bbox_vis, gt_mask_vis =\\\n",
    "        #    modellib.load_image_gt(dataset_val, config,i)\n",
    "        #visualize.display_instances(orig_image_vis, gt_bbox_vis, gt_mask_vis, gt_class_id_vis, dataset_val.class_names, title=\"GT\", figsize=(8, 8))\n",
    "        \n",
    "        t = time.time()\n",
    "        r = model_mrcnn.detect([image], verbose=0)[0]\n",
    "        \n",
    "        #visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "        #                        dataset_val.class_names, r['scores'], title=fnameP, ax=get_ax())\n",
    "    \n",
    "        threshold=0.5\n",
    "        res_mask=r['masks']\n",
    "        res_mask=np.where(res_mask >= threshold, 1, 0).astype(np.bool)\n",
    "        #AP_x, precisions_x, recalls_x, overlaps_x =\\\n",
    "        #    utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "        #                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], res_mask)\n",
    "        \n",
    "        \n",
    "        #print(\"RCNN Mask shape b4 summation\",r['masks'].shape)\n",
    "        \n",
    "        \n",
    "        #### Converting the gt and pred mask into binary semantic segmentation ###\n",
    "        gt_mask_4unet=gt_mask\n",
    "        gt_mask = np.sum(gt_mask,axis=2)\n",
    "        gt_mask = np.expand_dims(gt_mask,axis=2)\n",
    "                \n",
    "        rcnn_mask = np.sum(r['masks'],axis=2)\n",
    "        #rcnn_mask = np.where(rcnn_mask>1.0,1.0,rcnn_mask)\n",
    "        rcnn_mask = np.expand_dims(rcnn_mask,axis=2)\n",
    "        \n",
    "        rmask=np.sum(res_mask,axis=2)\n",
    "        #rcnn_mask = np.where(rcnn_mask>1.0,1.0,rcnn_mask)\n",
    "        rmask = np.expand_dims(rmask,axis=2)\n",
    "        \n",
    "        \n",
    "        #print(\"GT Mask shape after summation\",gt_mask.dtype)\n",
    "        #print(\"RCNN Mask shape after summation\",rmask.dtype)\n",
    "        IoU_rcnn=iou_score(rmask,gt_mask)\n",
    "        d_score=dice_score(rmask,gt_mask)\n",
    "        #print(\"mAP MRCNN\", AP_x)\n",
    "        #print(\"IoU Score MRCNN\", IoU_rcnn)\n",
    "        #print(\"DICE MRCNN\",d_score)\n",
    "        #print(\"===========================\")\n",
    "        avg_iou_rcnn.append(IoU_rcnn)\n",
    "        avg_dice_rcnn.append(d_score)\n",
    "        \n",
    "        \n",
    "        rcnn_mask=padIfNeeded(rcnn_mask, 1504, 1984)\n",
    "        rcnn_mask=np.expand_dims(rcnn_mask,axis=2)\n",
    "        #print(\"RCNN Mask shape after padding and 2 times expndDims\",rcnn_mask.shape)\n",
    "        \n",
    "        #visualize_unet(\n",
    "        #   predrcnn_msk=rcnn_mask[..., 0],\n",
    "            #bg_mask=bg_mask[..., 1].squeeze()\n",
    "        #)\n",
    "        \n",
    "        ## UNET MODEL as a Base Learner #########\n",
    "        image, gt_mask_unet = test_dataset[i]\n",
    "        \n",
    "        gt_mask_unet=gt_mask_unet[:,:,0:1]\n",
    "        \n",
    "        \n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        unet_mask = model_unet.predict(image)\n",
    "        \n",
    "        unet_mask=unet_mask.squeeze()\n",
    "        unet_mask=unet_mask[:,:,0:1]\n",
    "        \n",
    "        #print(\"UNET Mask shape\",unet_mask.shape)\n",
    "        #print(\"GT unet Mask shape\",gt_mask_unet.shape)\n",
    "        \n",
    "        iou_unet=iou_score(gt_mask_unet,unet_mask.round())\n",
    "        d_score=dice_score(gt_mask_unet.astype(int),unet_mask.round())  \n",
    "        \n",
    "        #visualize_unet(\n",
    "        #   unet_mask=unet_mask[..., 0],\n",
    "            #bg_mask=bg_mask[..., 1].squeeze()\n",
    "        #)\n",
    "        \n",
    "        #unet_mask_inst=bin_mask_splitter(unet_mask.round())\n",
    "        #gt_mask_inst=bin_mask_splitter(gt_mask_unet)\n",
    "        \n",
    "            \n",
    "        \n",
    "        #print(\"UNET Mask shape after morph\",unet_mask_inst.dtype)\n",
    "        #print(\"GT unet Mask shape after morph\",gt_mask_inst.shape)\n",
    "        \n",
    "        #mAP_val=mAP(gt_mask_inst,unet_mask_inst)\n",
    "        #print(\"IoU Unet\",iou_unet)\n",
    "        #print(\"DICE UNET\",d_score)\n",
    "        #print(\"===========================\")\n",
    "        #print(\"MAP UNET\",mAP_val)\n",
    "        avg_iou_unet.append(iou_unet)\n",
    "        avg_dice_unet.append(d_score)\n",
    "        \n",
    "        \n",
    "        ##### Weighted Average Ensemble ######################\n",
    "        w = normalize(w)\n",
    "        ensemble_mask=w[0]*unet_mask+w[1]*rcnn_mask\n",
    "        ensemble_mask=ensemble_mask.round()\n",
    "        \n",
    "        #visualize_unet(\n",
    "        #   ensemble_mask=ensemble_mask[..., 0],\n",
    "            #bg_mask=bg_mask[..., 1].squeeze()\n",
    "        #)\n",
    "        \n",
    "        iou_ensemble=iou_score(gt_mask_unet,ensemble_mask)\n",
    "        d_score=dice_score(gt_mask_unet,ensemble_mask)\n",
    "        #print(\"ENSEMBLE IOU SCORE\",iou_ensemble)\n",
    "        #print(\"ENSEMBLE DICE\",d_score)\n",
    "        #print(\"==========================\")\n",
    "        avg_iou_ens.append(iou_ensemble)\n",
    "        avg_dice_ens.append(d_score)\n",
    "        t_total=time.time()-t\n",
    "        #print(\"Pred Time\",t_total)\n",
    "        \n",
    "        \n",
    "    return 1-np.mean(avg_iou_ens)\n",
    "\n",
    "def normalize(weights):\n",
    "\t# calculate l1 vector norm\n",
    "\tresult = norm(weights, 1)\n",
    "\t# check for a vector of all zeros\n",
    "\tif result == 0.0:\n",
    "\t\treturn weights\n",
    "\t# return normalized vector (unit norm)\n",
    "\treturn weights / result\n",
    "\n",
    "\n",
    "def grid_search():\n",
    "    # define weights to consider\n",
    "    w = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    best_score, best_weights = 0.0, None\n",
    "    # iterate all possible combinations (cartesian product)\n",
    "    for weights in product(w, repeat=2):\n",
    "        # skip if all weights are equal\n",
    "        if len(set(weights)) == 1:\n",
    "            continue\n",
    "        # hack, normalize weight vector\n",
    "        weights = normalize(weights)\n",
    "        # evaluate weights\n",
    "        score = ensemble_prediction(weights)\n",
    "        print(\"Output for:\",weights)\n",
    "        if score > best_score:\n",
    "            best_score, best_weights = score, weights\n",
    "            print('>%s %.3f' % (best_weights, best_score))\n",
    "    return list(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ids = np.arange(len(test_dataset))\n",
    "\n",
    "avg_iou_rcnn=[]\n",
    "avg_iou_unet=[]\n",
    "avg_iou_ens=[]\n",
    "\n",
    "avg_dice_rcnn=[]\n",
    "avg_dice_unet=[]\n",
    "avg_dice_ens=[]\n",
    "\n",
    "avg_prec_unet=[]\n",
    "avg_rec_unet=[]\n",
    "\n",
    "\n",
    "avg_prec=[]\n",
    "avg_rec=[]\n",
    "\n",
    "map_rcnn=[]\n",
    "map_unet=[]\n",
    "map_ens=[]\n",
    "\n",
    "#ids = (8,12,15,16)\n",
    "\n",
    "for i in ids:\n",
    "    \n",
    "    image = dataset_val.load_image(i)\n",
    "\n",
    "    config.IMAGE_RESIZE_MODE=\"none\"\n",
    "    orig_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config,i)\n",
    "    \n",
    "    #image_rcnn = image.astype(np.uint8)\n",
    "    #image = dataset_val.load_image(i)\n",
    "    #print(\"MRNN DTP\",image.dtype)\n",
    "    config.IMAGE_RESIZE_MODE=\"square\"\n",
    "    orig_image_vis, image_meta_vis, gt_class_id_vis, gt_bbox_vis, gt_mask_vis =\\\n",
    "        modellib.load_image_gt(dataset_val, config,i)\n",
    "    visualize.display_instances(orig_image_vis, gt_bbox_vis, gt_mask_vis, gt_class_id_vis, dataset_val.class_names, title=\"GT\", figsize=(8, 8))\n",
    "    \n",
    "    t = time.time()\n",
    "    r = model_mrcnn.detect([image], verbose=0)[0]\n",
    "    \n",
    "    threshold=0.5\n",
    "    res_mask=r['masks']\n",
    "    res_mask=np.where(res_mask >= threshold, 1, 0).astype(np.bool)\n",
    "    \n",
    "    visualize.display_instances(image, r['rois'], res_mask, r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], title=fnameP, ax=get_ax())\n",
    "\n",
    "    \n",
    "    AP_x, precisions_x, recalls_x, overlaps_x =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], res_mask)\n",
    "    \n",
    "    \n",
    "    #print(\"RCNN Mask shape b4 summation\",r['masks'].shape)\n",
    "    \n",
    "    \n",
    "    #### Converting the gt and pred mask into binary semantic segmentation ###\n",
    "    gt_mask_4unet=gt_mask\n",
    "    gt_mask = np.sum(gt_mask,axis=2)\n",
    "    gt_mask = np.expand_dims(gt_mask,axis=2)\n",
    "            \n",
    "    visualize_unet(\n",
    "       gt_mask=gt_mask[..., 0],\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    ) \n",
    "    \n",
    "    rcnn_mask = np.sum(r['masks'],axis=2)\n",
    "    #rcnn_mask = np.where(rcnn_mask>1.0,1.0,rcnn_mask)\n",
    "    rcnn_mask = np.expand_dims(rcnn_mask,axis=2)\n",
    "    \n",
    "    rmask=np.sum(res_mask,axis=2)\n",
    "    #rcnn_mask = np.where(rcnn_mask>1.0,1.0,rcnn_mask)\n",
    "    rmask = np.expand_dims(rmask,axis=2)\n",
    "    \n",
    "    \n",
    "    print(\"GT Mask shape after summation\",gt_mask.dtype)\n",
    "    print(\"RCNN Mask shape after summation\",rmask.dtype)\n",
    "    IoU_rcnn=iou_score(rmask,gt_mask)\n",
    "    d_score=dice_score(rmask,gt_mask)\n",
    "    map_maskrcnn=map_t(gt_mask,rmask)\n",
    "    #print(\"mAP MRCNN\", AP_x)\n",
    "    print(\"IoU Score MRCNN\", IoU_rcnn)\n",
    "    print(\"DICE MRCNN\",d_score)\n",
    "    print(\"MAP rcnn\",map_maskrcnn)\n",
    "    print(\"===========================\")\n",
    "    avg_iou_rcnn.append(IoU_rcnn)\n",
    "    avg_dice_rcnn.append(d_score)\n",
    "    map_rcnn.append(map_maskrcnn)\n",
    "    \n",
    "    rcnn_mask=padIfNeeded(rcnn_mask, 1504, 1984)\n",
    "    rcnn_mask=np.expand_dims(rcnn_mask,axis=2)\n",
    "    #print(\"RCNN Mask shape after padding and 2 times expndDims\",rcnn_mask.shape)\n",
    "    \n",
    "    visualize_unet(\n",
    "       predrcnn_msk=rcnn_mask[..., 0].round(),\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    )\n",
    "    \n",
    "    ## UNET MODEL as a Base Learner #########\n",
    "    image, gt_mask_unet = test_dataset[i]\n",
    "    \n",
    "    gt_mask_unet=gt_mask_unet[:,:,0:1]\n",
    "    \n",
    "    \n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    unet_mask = model_unet.predict(image)\n",
    "    \n",
    "    unet_mask=unet_mask.squeeze()\n",
    "    unet_mask=unet_mask[:,:,0:1]\n",
    "    \n",
    "    #print(\"UNET Mask shape\",unet_mask.shape)\n",
    "    #print(\"GT unet Mask shape\",gt_mask_unet.shape)\n",
    "    \n",
    "    iou_unet=iou_score(gt_mask_unet,unet_mask.round())\n",
    "    d_score=dice_score(gt_mask_unet.astype(int),unet_mask.round())  \n",
    "    prec,recall=precision_recall(gt_mask_unet,unet_mask.round())\n",
    "    map_unett=map_t(gt_mask_unet,unet_mask.round())\n",
    "    \n",
    "    visualize_unet(\n",
    "       unet_mask=unet_mask[..., 0].round(),\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    )\n",
    "    \n",
    "    #unet_mask_inst=bin_mask_splitter(unet_mask.round())\n",
    "    #gt_mask_inst=bin_mask_splitter(gt_mask_unet)\n",
    "    \n",
    "        \n",
    "    \n",
    "    #print(\"UNET Mask shape after morph\",unet_mask_inst.dtype)\n",
    "    #print(\"GT unet Mask shape after morph\",gt_mask_inst.shape)\n",
    "    \n",
    "    #mAP_val=mAP(gt_mask_inst,unet_mask_inst)\n",
    "    print(\"IoU Unet\",iou_unet)\n",
    "    print(\"DICE UNET\",d_score)\n",
    "    print(\"Prec UNET\",prec)\n",
    "    print(\"Rec Unet\",recall)\n",
    "    print(\"mAP UNET\",map_unett)\n",
    "    print(\"===========================\")\n",
    "    #print(\"MAP UNET\",mAP_val)\n",
    "    avg_iou_unet.append(iou_unet)\n",
    "    avg_dice_unet.append(d_score)\n",
    "    avg_prec_unet.append(prec)\n",
    "    avg_rec_unet.append(recall)\n",
    "    map_unet.append(map_unett)\n",
    "    \n",
    "    ##### Weighted Average Ensemble ######################\n",
    "    ##0.625 0.375\n",
    "    ensemble_mask=0.625*unet_mask+0.375*rcnn_mask\n",
    "    ensemble_mask=ensemble_mask.round()\n",
    "    \n",
    "    visualize_unet(\n",
    "       ensemble_mask=ensemble_mask[..., 0],\n",
    "        #bg_mask=bg_mask[..., 1].squeeze()\n",
    "    )\n",
    "    \n",
    "    iou_ensemble=iou_score(gt_mask_unet,ensemble_mask)\n",
    "    d_score=dice_score(gt_mask_unet,ensemble_mask)\n",
    "    prec,recall=precision_recall(gt_mask_unet,ensemble_mask)\n",
    "    map_enss=map_t(gt_mask_unet,ensemble_mask)\n",
    "    print(\"ENSEMBLE IOU SCORE\",iou_ensemble)\n",
    "    print(\"ENSEMBLE DICE\",d_score)\n",
    "    print(\"Ensemble Prec\", prec)\n",
    "    print(\"Ensemble Recall\", recall)\n",
    "    print(\"Ensemble MAP\",map_enss)\n",
    "    map_ens.append(map_enss)\n",
    "    if not np.any(gt_mask_unet) and not np.any(ensemble_mask):\n",
    "        print(\"GOOD CORK\")\n",
    "        avg_iou_ens.append(1)\n",
    "        avg_dice_ens.append(1)\n",
    "        avg_prec.append(1)\n",
    "        avg_rec.append(1)\n",
    "    else:\n",
    "        \n",
    "        avg_iou_ens.append(iou_ensemble)\n",
    "        avg_dice_ens.append(d_score)\n",
    "        avg_prec.append(prec)\n",
    "        avg_rec.append(recall)\n",
    "    print(\"==========================\")\n",
    "    t_total=time.time()-t\n",
    "    print(\"Pred Time\",t_total)\n",
    "    \n",
    "    \n",
    "print(\"IOU MRCNN\", np.mean(avg_iou_rcnn))\n",
    "print(\"IOU UNET\", np.mean(avg_iou_unet))\n",
    "print(\"IOU of Ensemble\", np.mean(avg_iou_ens))\n",
    "\n",
    "    \n",
    "print(\"Dice MRCNN\", np.mean(avg_dice_rcnn))\n",
    "print(\"Dice UNET\", np.mean(avg_dice_unet))\n",
    "print(\"Dice of Ensemble\", np.mean(avg_dice_ens))\n",
    "    \n",
    "print(\"Prec UNET\", np.mean(avg_prec_unet))\n",
    "print(\"Recall UNET\", np.mean(avg_rec_unet))\n",
    "print(\"Prec of Ensemble\", np.mean(avg_prec))\n",
    "print(\"Recall of Ensemble\", np.mean(avg_rec)) \n",
    "\n",
    "print(\"map MRCNN\", np.mean(map_rcnn))\n",
    "print(\"map UNET\", np.mean(map_unet))\n",
    "print(\"map of Ensemble\", np.mean(map_ens))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble PloT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iou_t=[0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95]\n",
    "rcnn_iou=[]\n",
    "unet_iou=[]\n",
    "ens_iou=[]\n",
    "for th in iou_t:\t\n",
    "\tids = np.arange(len(test_dataset))\n",
    "\t\n",
    "\tavg_iou_rcnn=[]\n",
    "\tavg_iou_unet=[]\n",
    "\tavg_iou_ens=[]\n",
    "\t\n",
    "\tavg_dice_rcnn=[]\n",
    "\tavg_dice_unet=[]\n",
    "\tavg_dice_ens=[]\n",
    "\t\n",
    "\tavg_prec_unet=[]\n",
    "\tavg_rec_unet=[]\n",
    "\t\n",
    "\t\n",
    "\tavg_prec=[]\n",
    "\tavg_rec=[]\n",
    "\t\n",
    "\tmap_rcnn=[]\n",
    "\tmap_unet=[]\n",
    "\tmap_ens=[]\n",
    "\t\n",
    "\t#ids = (8,12,15,16)\n",
    "\t\n",
    "\tfor i in ids:\n",
    "\t\t\n",
    "\t\timage = dataset_val.load_image(i)\n",
    "\t\n",
    "\t\tconfig.IMAGE_RESIZE_MODE=\"none\"\n",
    "\t\torig_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "\t\t\tmodellib.load_image_gt(dataset_val, config,i)\n",
    "\t\t\n",
    "\t\t#image_rcnn = image.astype(np.uint8)\n",
    "\t\t#image = dataset_val.load_image(i)\n",
    "\t\t#print(\"MRNN DTP\",image.dtype)\n",
    "\t\tconfig.IMAGE_RESIZE_MODE=\"square\"\n",
    "\t\torig_image_vis, image_meta_vis, gt_class_id_vis, gt_bbox_vis, gt_mask_vis =\\\n",
    "\t\t\tmodellib.load_image_gt(dataset_val, config,i)\n",
    "\t\t#visualize.display_instances(orig_image_vis, gt_bbox_vis, gt_mask_vis, gt_class_id_vis, dataset_val.class_names, title=\"GT\", figsize=(8, 8))\n",
    "\t\t\n",
    "\t\tt = time.time()\n",
    "\t\tr = model_mrcnn.detect([image], verbose=0)[0]\n",
    "\t\t\n",
    "\t\t#visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "\t\t#                        dataset_val.class_names, r['scores'], title=fnameP, ax=get_ax())\n",
    "\t\n",
    "\t\tthreshold=0.5\n",
    "\t\tres_mask=r['masks']\n",
    "\t\tres_mask=np.where(res_mask >= threshold, 1, 0).astype(np.bool)\n",
    "\t\tAP_x, precisions_x, recalls_x, overlaps_x =\\\n",
    "\t\t\tutils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "\t\t\t\t\t\t\tr[\"rois\"], r[\"class_ids\"], r[\"scores\"], res_mask)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#print(\"RCNN Mask shape b4 summation\",r['masks'].shape)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#### Converting the gt and pred mask into binary semantic segmentation ###\n",
    "\t\tgt_mask_4unet=gt_mask\n",
    "\t\tgt_mask = np.sum(gt_mask,axis=2)\n",
    "\t\tgt_mask = np.expand_dims(gt_mask,axis=2)\n",
    "\t\t\t\t\n",
    "\t\tvisualize_unet(\n",
    "\t\tgt_mask=gt_mask[..., 0],\n",
    "\t\t\t#bg_mask=bg_mask[..., 1].squeeze()\n",
    "\t\t) \n",
    "\t\t\n",
    "\t\trcnn_mask = np.sum(r['masks'],axis=2)\n",
    "\t\t#rcnn_mask = np.where(rcnn_mask>1.0,1.0,rcnn_mask)\n",
    "\t\trcnn_mask = np.expand_dims(rcnn_mask,axis=2)\n",
    "\t\t\n",
    "\t\trmask=np.sum(res_mask,axis=2)\n",
    "\t\t#rcnn_mask = np.where(rcnn_mask>1.0,1.0,rcnn_mask)\n",
    "\t\trmask = np.expand_dims(rmask,axis=2)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tprint(\"GT Mask shape after summation\",gt_mask.dtype)\n",
    "\t\tprint(\"RCNN Mask shape after summation\",rmask.dtype)\n",
    "\t\tIoU_rcnn=iou_score(rmask,gt_mask)\n",
    "\t\td_score=dice_score(rmask,gt_mask)\n",
    "\t\tmap_maskrcnn=map_t(gt_mask,rmask,th)\n",
    "\t\t#print(\"mAP MRCNN\", AP_x)\n",
    "\t\tprint(\"IoU Score MRCNN\", IoU_rcnn)\n",
    "\t\tprint(\"DICE MRCNN\",d_score)\n",
    "\t\tprint(\"MAP rcnn\",map_maskrcnn)\n",
    "\t\tprint(\"===========================\")\n",
    "\t\tavg_iou_rcnn.append(IoU_rcnn)\n",
    "\t\tavg_dice_rcnn.append(d_score)\n",
    "\t\tmap_rcnn.append(map_maskrcnn)\n",
    "\t\t\n",
    "\t\trcnn_mask=padIfNeeded(rcnn_mask, 1504, 1984)\n",
    "\t\trcnn_mask=np.expand_dims(rcnn_mask,axis=2)\n",
    "\t\t#print(\"RCNN Mask shape after padding and 2 times expndDims\",rcnn_mask.shape)\n",
    "\t\t\n",
    "\t\tvisualize_unet(\n",
    "\t\tpredrcnn_msk=rcnn_mask[..., 0].round(),\n",
    "\t\t\t#bg_mask=bg_mask[..., 1].squeeze()\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t## UNET MODEL as a Base Learner #########\n",
    "\t\timage, gt_mask_unet = test_dataset[i]\n",
    "\t\t\n",
    "\t\tgt_mask_unet=gt_mask_unet[:,:,0:1]\n",
    "\t\t\n",
    "\t\t\n",
    "\t\timage = np.expand_dims(image, axis=0)\n",
    "\t\tunet_mask = model_unet.predict(image)\n",
    "\t\t\n",
    "\t\tunet_mask=unet_mask.squeeze()\n",
    "\t\tunet_mask=unet_mask[:,:,0:1]\n",
    "\t\t\n",
    "\t\t#print(\"UNET Mask shape\",unet_mask.shape)\n",
    "\t\t#print(\"GT unet Mask shape\",gt_mask_unet.shape)\n",
    "\t\t\n",
    "\t\tiou_unet=iou_score(gt_mask_unet,unet_mask.round())\n",
    "\t\td_score=dice_score(gt_mask_unet.astype(int),unet_mask.round())  \n",
    "\t\tprec,recall=precision_recall(gt_mask_unet,unet_mask.round())\n",
    "\t\tmap_unett=map_t(gt_mask_unet,unet_mask.round(),th)\n",
    "\t\t\n",
    "\t\tvisualize_unet(\n",
    "\t\tunet_mask=unet_mask[..., 0].round(),\n",
    "\t\t\t#bg_mask=bg_mask[..., 1].squeeze()\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t#unet_mask_inst=bin_mask_splitter(unet_mask.round())\n",
    "\t\t#gt_mask_inst=bin_mask_splitter(gt_mask_unet)\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\t\n",
    "\t\t#print(\"UNET Mask shape after morph\",unet_mask_inst.dtype)\n",
    "\t\t#print(\"GT unet Mask shape after morph\",gt_mask_inst.shape)\n",
    "\t\t\n",
    "\t\t#mAP_val=mAP(gt_mask_inst,unet_mask_inst)\n",
    "\t\tprint(\"IoU Unet\",iou_unet)\n",
    "\t\tprint(\"DICE UNET\",d_score)\n",
    "\t\tprint(\"Prec UNET\",prec)\n",
    "\t\tprint(\"Rec Unet\",recall)\n",
    "\t\tprint(\"mAP UNET\",map_unett)\n",
    "\t\tprint(\"===========================\")\n",
    "\t\t#print(\"MAP UNET\",mAP_val)\n",
    "\t\tavg_iou_unet.append(iou_unet)\n",
    "\t\tavg_dice_unet.append(d_score)\n",
    "\t\tavg_prec_unet.append(prec)\n",
    "\t\tavg_rec_unet.append(recall)\n",
    "\t\tmap_unet.append(map_unett)\n",
    "\t\t\n",
    "\t\t##### Weighted Average Ensemble ######################\n",
    "\t\t##0.625 0.375\n",
    "\t\tensemble_mask=0.625*unet_mask+0.375*rcnn_mask\n",
    "\t\tensemble_mask=ensemble_mask.round()\n",
    "\t\t\n",
    "\t\tvisualize_unet(\n",
    "\t\tensemble_mask=ensemble_mask[..., 0],\n",
    "\t\t\t#bg_mask=bg_mask[..., 1].squeeze()\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tiou_ensemble=iou_score(gt_mask_unet,ensemble_mask)\n",
    "\t\td_score=dice_score(gt_mask_unet,ensemble_mask)\n",
    "\t\tprec,recall=precision_recall(gt_mask_unet,ensemble_mask)\n",
    "\t\tmap_enss=map_t(gt_mask_unet,ensemble_mask,th)\n",
    "\t\tprint(\"ENSEMBLE IOU SCORE\",iou_ensemble)\n",
    "\t\tprint(\"ENSEMBLE DICE\",d_score)\n",
    "\t\tprint(\"Ensemble Prec\", prec)\n",
    "\t\tprint(\"Ensemble Recall\", recall)\n",
    "\t\tprint(\"Ensemble MAP\",map_enss)\n",
    "\t\tmap_ens.append(map_enss)\n",
    "\t\tif not np.any(gt_mask_unet) and not np.any(ensemble_mask):\n",
    "\t\t\tprint(\"GOOD CORK\")\n",
    "\t\t\tavg_iou_ens.append(1)\n",
    "\t\t\tavg_dice_ens.append(1)\n",
    "\t\t\tavg_prec.append(1)\n",
    "\t\t\tavg_rec.append(1)\n",
    "\t\telse:\n",
    "\t\t\t\n",
    "\t\t\tavg_iou_ens.append(iou_ensemble)\n",
    "\t\t\tavg_dice_ens.append(d_score)\n",
    "\t\t\tavg_prec.append(prec)\n",
    "\t\t\tavg_rec.append(recall)\n",
    "\t\tprint(\"==========================\")\n",
    "\t\tt_total=time.time()-t\n",
    "\t\tprint(\"Pred Time\",t_total)\n",
    "\t\t\n",
    "\tprint(\"IOU threshold\",th)\n",
    "\trcnn_iou.append(np.mean(map_rcnn))\n",
    "\tunet_iou.append(np.mean(map_unet))\n",
    "\tens_iou.append(np.mean(map_ens))\n",
    "\tprint(\"map mask rcnn\",np.mean(map_rcnn))\n",
    "\tprint(\"map unet\",np.mean(map_unet))\n",
    "\tprint(\"map ens\",np.mean(map_ens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.grid()\n",
    "plt.plot(iou_t,xrcnn_iou,iou_t,xunet_iou,':',iou_t,xens_iou,'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dice_score(mask1, mask2):\n",
    "    intersection = np.sum((mask1 + mask2)==2)\n",
    "    summation=np.sum(mask1 + mask2)\n",
    "    if summation==0:\n",
    "        return 1\n",
    "    score=(2*intersection)/summation\n",
    "    return score\n",
    "    \n",
    "def map_t(gt_mask,pred_mask,iou_threshold=0.5):\n",
    "    gt_mask=bin_mask_splitter(gt_mask)\n",
    "    pred_mask=bin_mask_splitter(pred_mask)\n",
    "    \n",
    "    #if np.all(gt_mask)==0.0:\n",
    "    #    if np.all(pred_mask)==0.0:\n",
    "    #        return 1\n",
    "    #    else:\n",
    "    #        return 0\n",
    "    ch_1 = gt_mask.shape[2]\n",
    "    ch_2 = pred_mask.shape[2]\n",
    "    \n",
    "    p_match=-1*np.ones(ch_2)\n",
    "    \n",
    "    for i in range(ch_2):\n",
    "        for j in range(ch_1):\n",
    "            if np.any(gt_mask[:,:,j]+pred_mask[:,:,i]==2):\n",
    "                IoU_score=iou_score(gt_mask[:,:,j], pred_mask[:,:,i])\n",
    "            \n",
    "                if IoU_score>=iou_threshold:\n",
    "                    p_match[i]=1\n",
    "                    \n",
    "    precisions = np.cumsum(p_match > -1) / (np.arange(len(p_match)) + 1)\n",
    "    recalls = np.cumsum(p_match > -1).astype(np.float32) / gt_mask.shape[2]\n",
    "    \n",
    "    precisions = np.concatenate([[0], precisions, [0]])\n",
    "    recalls = np.concatenate([[0], recalls, [1]])\n",
    "\n",
    "    # Ensure precision values decrease but don't increase. This way, the\n",
    "    # precision value at each recall threshold is the maximum it can be\n",
    "    # for all following recall thresholds, as specified by the VOC paper.\n",
    "    for i in range(len(precisions) - 2, -1, -1):\n",
    "        precisions[i] = np.maximum(precisions[i], precisions[i + 1])\n",
    "\n",
    "    # Compute mean AP over recall range\n",
    "    indices = np.where(recalls[:-1] != recalls[1:])[0] + 1\n",
    "    mAP_val = np.sum((recalls[indices] - recalls[indices - 1]) *\n",
    "                 precisions[indices])\n",
    "    \n",
    "    return mAP_val\n",
    "    \n",
    "def precision_recall(gt_mask, pred_mask, iou_threshold=0.5):    \n",
    "    gt_mask=bin_mask_splitter(gt_mask)\n",
    "    pred_mask=bin_mask_splitter(pred_mask)\n",
    "    \n",
    "    ch_1 = gt_mask.shape[2]\n",
    "    ch_2 = pred_mask.shape[2]\n",
    "    \n",
    "    tp=0\n",
    "    \n",
    "    for i in range(ch_2):\n",
    "        for j in range(ch_1):\n",
    "            if np.any(gt_mask[:,:,j]+pred_mask[:,:,i]==2):\n",
    "                IoU_score=iou_score(gt_mask[:,:,j], pred_mask[:,:,i])\n",
    "            \n",
    "                if IoU_score>=iou_threshold:\n",
    "                    tp=tp+1\n",
    "    fp=ch_2-tp                \n",
    "    recall=tp/ch_1\n",
    "    prec=tp/(tp+fp)\n",
    "    return (prec,recall)\n",
    "    \n",
    "mask_unet1 = np.array([[0,0,0,0,0,0],[0,1,1,0,0,0],[0,0,1,1,0,0],[0,0,0,0,0,0]])\n",
    "mask_unet2 = np.array([[0,0,0,0,0,1],[0,0,1,0,1,1],[0,0,1,1,0,1],[0,0,0,0,0,0]])\n",
    "\n",
    "dice_score(mask_unet1,mask_unet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize\n",
    "\n",
    "\n",
    "def f(w):\n",
    "    x=w[0]-w[1]\n",
    "    return x\n",
    "\n",
    "\n",
    "res = gp_minimize(ensemble_prediction,                  # the function to minimize\n",
    "                  [(0.0, 1.0),(0.0, 1.0)],      # the bounds on each dimension of x\n",
    "                  acq_func=\"EI\",      # the acquisition function\n",
    "                  n_calls=20,         # the number of evaluations of f\n",
    "                  n_random_starts=5,  # the number of random initialization points\n",
    "                  random_state=1234)\n",
    "\n",
    "res.x[0],res.x[1], res.fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.DETECTION_MIN_CONFIDENCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
